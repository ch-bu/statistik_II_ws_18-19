---
title: "Statistik II - Nachbereitungsaufgabe"
subtitle: "03 Stichprobenverteilung und Parameterschätzung"
author: ""
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Revision deiner Erklärung zum Thema Stichprobenverteilung und Parameterschätzung

Als Vorbereitungsaufgaben hast du eine Erklärung zum Thema Stichprobenverteilung und Parameterschätzung geschrieben. Nun sollst du diese Erklärung revidieren. Revidieren bedeutet, dass du (1) deine Erklärung auf Richtigkeit und Korrektheit überprüfst, und (2) deine Erklärung nach den Kriterien der Richtigkeit und Korrektheit überarbeitest. Achte bei dieser Revision auf folgender Leitfragen:

* Hast du in das übergeordnete Thema deiner Erklärung eingeführt? 
* Hast du die relevanten Konzepte deiner Erklärung benannt und ausreichend erklärt? 
* Hast du die relevanten Konzepte deiner Erklärung logisch und sinnvoll miteinander verbunden? 
* Hast du die relevanten Konzepte deiner Erklärung durch gute Beispiele illustriert? 

Nimm dir für die Revision deiner Erklärung in etwa 45 Minuten Zeit und versuche auf die Erklärung hinsichtlich dieser Leitfragen zu überarbeiten. 

> TODO: Füge hier deine revidierte Erklärung ein.


## Fragen zur Revision

Wie lange hast du an der Revision geschrieben? 

> TODO: Bitte in Minuten angeben

Wie stark hast du dich gerade bei der Revisions der Erklärung angestrengt (1: Sehr stark angestrengt; 9: gar nicht angestrengt)?  

> TODO: Bitte Antwort hier eintragen

Wie schwierig war es für dich die Erklärung zu revidieren (1: Sehr schwierig, 9 gar nicht schwierig)? 

> TODO: Bitte Antwort hier eintragen

Wie verständlich schätzt du deine revidierte Erklärung ein (1: Sehr verständlich; 5 gar nicht verständlich)? 

> TODO: Bitte Antwort hier eintragen

# R Anwendungsaufgaben

```{r message=FALSE}
library(tidyverse)
```

### Der Titanicdatensatz

In dieser Nachbereitungsaufgabe beschäftigen wir uns mit den Passagieren der Titanic. Zunächst müssen wir den Datensatz `titanic.csv` als Tibble einlesen:

```{r}
# TODO: Lese den Datensatz mit read_csv ein
#       titanic.csv und weise dem Datensatz die Variable
#       titanic zu
```

Welche Variablennamen umfasst der Datensatz? Gebe dir die Variablennamen mit `colnames` aus:

```{r}
# TODO: colnames nutzen
```

Es gibt ein paar interessante Variablen. Schauen wir mal, wie viele der `r nrow(titanic)` Passagiere überlebt haben? Nutze hierfür den Pipe-Operator und die Funktion [count](https://dplyr.tidyverse.org/reference/tally.html). 0 bedeutet gestorben, 1 bedeutet überlebt.

```{r}
# TODO: Überlebende zählen
```

Aha, die Mehrzahl der Passagiere ist gestorben. Man sagt immer, dass Personen der dritten Klasse schlechtere Chancen hatten zu überleben, stimmt das? Verwende wieder die `count`-Funktion und übergebe als Argumente die Variablen `survived` und `pclass`. 

```{r}
# TODO: Überlebende nach Klasse zählen
#       Weiße den Output der Variable survived_per_class zu:

# survived_per_class <- NULL
```

Aus der Tabelle können wir nicht wirklich einfach unsere Frage beantworten. Machen wir einen Balkendiagram daraus. 

Da wir diese Zahlen als Balkendiagram visualisieren möchten, müssen wir die Variable pclass zunächst von einem Integer in einen Faktor umwandeln (siehe glimpse) und das Ergebnis nach den überlebenden [filtern](https://dplyr.tidyverse.org/reference/filter.html):

```{r}
died_per_class <- survived_per_class %>%
  mutate(
    pclass = factor(pclass)
  ) %>%
  filter(survived == 0)
```

Jetzt können wir die überlebenden nach Klasse visualisieren. Vervollständige hierfür den folgenden Code. Erstelle ein Balkendiagram (siehe [hier](https://ggplot2.tidyverse.org/reference/index.html)).

`
ggplot(died_per_class, aes(pclass, n, group = NULL)) +
  NULL(stat = "identity", aes(fill = pclass)) +
  xlab("Passagierklasse") +
  ylab("Anzahl der Überlebenden")
`

```{r}
# TODO: Balkendiagram erstellen
```

Wer war eigentlich der älteste Passagier auf der Titanic? Nutze [arrange](https://dplyr.tidyverse.org/reference/arrange.html) und [head](https://www.rdocumentation.org/packages/utils/versions/3.5.1/topics/head) und den Pipe-Operator, um die Fragen zu beantworten. 

```{r}
# TODO: Ältester Passagier
```


### Freiwillige Aufgabe: Zentrales Grenzwerttheorem 

Das zentrale Grenzwerttheorem bedeutet, dass Stichprobenkennwertverteilungen des Mittelwerts mit steigenden Stichproben einer Normalverteilung um den Populationsmittelwert entsprechen. In dieser Aufgabe simulieren wir das zentrale Grenzwerttheorem. 

Wir untersuchen das Grenzwerttheorem anhand der Variable `age` des Titanicdatensatzes:

```{r}
ggplot(titanic, aes(age)) +
  geom_histogram()
```

Diese Verteilung ist unsere Population. Um das zentrale Grenzwerttheorem zu testen, müssen wir aus dieser Population viele Stichproben ziehen. Auf Grundlage des zentralen Grenzwerttheorems erwarten wir, dass die Stichprobenkennwertverteilungen dieser Stichproben mit steigenden Stichproben sich einer Normalverteilung annähern. 

Wir beginnen mit einem einfachen Problem. Wie sieht die Stichprobenkennwertverteilung der Mittelwerte aus, wenn wir 20 Stichproben (N = 30) aus der Population ziehen? 

```{r}
samples_20 <- c(1:20) %>% 
  map(~ sample_n(titanic, 30) %>% {.$age}) %>%
  map_dbl(~ mean(., na.rm = TRUE))

hist(samples_20)
```

Ok, das sieht nicht nach einer Normalverteilung aus. Was passiert, wenn wir 50 Stichproben aus der Population ziehen und daraus unsere Stichprobenkennwertverteilung berechnen? 

```{r}
samples_20 <- c(1:50) %>% 
  map(~ sample_n(titanic, 30) %>% {.$age}) %>%
  map_dbl(~ mean(., na.rm = TRUE))

hist(samples_20)
```

Aha, das sieht schon mehr nach einer Normalverteilung aus. Versuchen wir als nächstes das Problem zu formalisieren, indem wir ganz viele dieser Simulationen umsetzen. Zunächst ist es sinnvoll, unseren Code zu Berechnung der Werte der Stichprobenverteilung in eine Funktion zu packen:

```{r}
create_sample_distribution <- function(number_of_samples, my_dataframe) {
  sample_means <- c(1:number_of_samples) %>% 
    map(~ sample_n(my_dataframe, 30) %>% {.$age}) %>%
    map_dbl(~ mean(., na.rm = TRUE))
  
  return(sample_means)
}
```

Schauen wir, ob die Funktion funktioniert:

```{r}
create_sample_distribution(20, titanic)
```

Sehr gut, wir können nun Stichprobenkennwertverteilungen für willkürliche N berechnen. Als nächstes möchten wir Stichprobenkennwertverteilungen von 1 bis 300 Stichproben mit dieser Funktion erstellen:

```{r}
create_multiple_sample_distributions <- function(dataframe) {
  sample_means <- seq(1, 300, by = 10) %>%
    map_dfr(~ tibble(sample      = rep(., .), 
                     sample_id   = c(1:.), 
                     sample_mean = create_sample_distribution(., titanic)))
  return(sample_means)
}

sample_means <- create_multiple_sample_distributions(titanic)
```

Diese Stichprobenkennwertverteilungen können wir nun visualisieren:

```{r}
ggplot(sample_means, aes(x = sample_mean)) +
  geom_histogram(binwidth = 1) +
  facet_wrap(~ sample) +
  xlab("Sample distributions") +
  ylab("Häufigkeit")
```

> TODO: Was kannst du aus dieser Visualisierung bezüglich des zentralen Grenzwerttheorems erkennen? 

Was passiert allerdings, wenn unsere ursprüngliche Verteilung nicht normalverteilt ist? 

```{r}
non_normal_distribution <- tibble(age = rnbinom(3000, 5, .5))

non_normal_distribution$age %>% hist
```

```{r}
sample_means_non_normal <- create_multiple_sample_distributions(non_normal_distribution)

ggplot(sample_means_non_normal, aes(x = sample_mean)) +
  geom_histogram(binwidth = 1) +
  facet_wrap(~ sample) +
  xlab("Sample distributions") +
  ylab("Häufigkeit")
```

> TODO: Beschreibe in deinen eigenen Worten, was du nun über das zentrale Grenzwerttheorem für nicht-normalverteilte Populationen sagen kannst. Versuche deine Antwort auf die nicht-normalverteilte Verteilung der Population zu beantworten. 
